Metadata-Version: 2.3
Name: ollama-haystack
Version: 0.0.6
Summary: An integration between the Ollama LLM framework and Haystack
Project-URL: Documentation, https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama#readme
Project-URL: Issues, https://github.com/deepset-ai/haystack-core-integrations/issues
Project-URL: Source, https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama
Author-email: Alistair Rogers <alistairlr112@gmail.com>, Sachin Sachdeva <emailforsachinsachdeva@gmail.com>, deepset GmbH <info@deepset.ai>
License-Expression: Apache-2.0
License-File: LICENSE.txt
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Requires-Python: >=3.8
Requires-Dist: haystack-ai
Requires-Dist: requests
Description-Content-Type: text/markdown

# ollama-haystack

[![PyPI - Version](https://img.shields.io/pypi/v/ollama-haystack.svg)](https://pypi.org/project/ollama-haystack)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ollama-haystack.svg)](https://pypi.org/project/ollama-haystack)

-----

**Table of Contents**

- [Installation](#installation)
- [License](#license)

## Installation

```console
pip install ollama-haystack
```

## License

`ollama-haystack` is distributed under the terms of the [Apache-2.0](https://spdx.org/licenses/Apache-2.0.html) license.

## Testing

To run tests first start a Docker container running Ollama and pull a model for integration testing
It's recommended to use the smallest model possible for testing purposes - see https://ollama.ai/library for a list that Ollama supportd

```console
docker run -d -p 11434:11434 --name ollama ollama/ollama:latest
docker exec ollama ollama pull <your model here>
```

Then run tests:

```console
hatch run test
```

The default model used here is ``orca-mini``