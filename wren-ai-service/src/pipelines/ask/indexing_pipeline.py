import json
import logging
import os
from typing import Any, Dict, List

import openai
from haystack import Document, Pipeline
from haystack.components.writers import DocumentWriter
from haystack.document_stores.types import DocumentStore, DuplicatePolicy
from tqdm import tqdm

from src.core.pipeline import BasicPipeline
from src.pipelines.ask.components.document_store import init_document_store
from src.pipelines.ask.components.embedder import (
    EMBEDDING_MODEL_DIMENSION,
    EMBEDDING_MODEL_NAME,
)
from src.utils import generate_ddls_from_semantics, load_env_vars

load_env_vars()
logger = logging.getLogger("wren-ai-service")

DATASET_NAME = os.getenv("DATASET_NAME")


class Indexing(BasicPipeline):
    def __init__(
        self,
        document_store: DocumentStore,
        view_store: DocumentStore,
        embedding_model_name: str = EMBEDDING_MODEL_NAME,
        embedding_model_dim: int = EMBEDDING_MODEL_DIMENSION,
    ) -> None:
        self._document_store = document_store
        self._view_store = view_store

        self._pipeline = Pipeline()
        # TODO: add a component to remove existing documents to fully delete old documents
        self._pipeline.add_component(
            "writer",
            DocumentWriter(
                document_store=document_store,
                policy=DuplicatePolicy.OVERWRITE,
            ),
        )

        self._openai_client = openai.Client(api_key=os.getenv("OPENAI_API_KEY"))

        self.embedding_model_name = embedding_model_name
        self.embedding_model_dim = embedding_model_dim

        super().__init__(self._pipeline)

    def run(self, mdl_str: str) -> Dict[str, Any]:
        logger.info("Ask Indexing pipeline is clearing old documents...")
        self._clear_documents(self._document_store)

        logger.info("Ask Indexing pipeline is writing new documents...")
        self._store_view_questions(mdl_str)
        return self._pipeline.run(
            {"writer": {"documents": self._get_documents(mdl_str)}}
        )

    def _store_view_questions(self, mdl_str: str) -> None:
        """
        Convert the view MDL to the following format:
        {
          "question":"user original query",
          "description":"the description generated by LLM",
          "statement":"the SQL statement generated by LLM"
        }
        and store it in the view store.
        """
        self._clear_documents(self._view_store)
        views = json.loads(mdl_str)["views"]

        def _format(view: Dict[str, Any]) -> List[str]:
            return str(
                {
                    "question": view["properties"]["question"],
                    "description": view["properties"]["description"],
                    "statement": view["statement"],
                }
            )

        converted_views = [_format(view) for view in views]

        if not converted_views:
            return

        embeddings = self._openai_client.embeddings.create(
            input=converted_views,
            model=self.embedding_model_name,
            dimensions=self.embedding_model_dim,
        )
        documents = [
            Document(
                id=str(i),
                meta={"id": str(i)},
                content=converted_view,
                embedding=embeddings.data[i].embedding,
            )
            for i, converted_view in enumerate(
                tqdm(
                    converted_views,
                    desc="indexing view into the historial view question store",
                )
            )
        ]

        self._view_store.write_documents(
            documents,
            policy=DuplicatePolicy.OVERWRITE,
        )

    def _clear_documents(self, store: DocumentStore) -> None:
        ids = [str(i) for i in range(store.count_documents())]
        if ids:
            store.delete_documents(ids)

    def _get_documents(self, mdl_str: str) -> List[Document]:
        mdl_json = json.loads(mdl_str)

        logger.debug(f"original mdl_json: {json.dumps(mdl_json, indent=2)}")

        for i, _ in enumerate(mdl_json["relationships"]):
            mdl_json["relationships"][i]["type"] = "relationship"

        semantics = {
            "models": [],
            "relationships": mdl_json["relationships"],
            "views": mdl_json["views"],
        }

        for model in mdl_json["models"]:
            columns = []
            for column in model["columns"]:
                ddl_column = {
                    "name": column["name"],
                    "properties": column["properties"],
                    "type": column["type"],
                    "isCalculated": column["isCalculated"],
                }
                if "relationship" in column:
                    ddl_column["relationship"] = column["relationship"]
                if "expression" in column:
                    ddl_column["expression"] = column["expression"]
                if column["isCalculated"]:
                    ddl_column["isCalculated"] = column["isCalculated"]

                columns.append(ddl_column)

            semantics["models"].append(
                {
                    "type": "model",
                    "name": model["name"],
                    "properties": model["properties"],
                    "columns": columns,
                    "primaryKey": model["primaryKey"],
                }
            )

        ddl_commands = generate_ddls_from_semantics(
            semantics["models"],
            semantics["relationships"],
        )

        ddl_commands.extend(self._convert_views(semantics["views"]))

        embeddings = self._openai_client.embeddings.create(
            input=ddl_commands,
            model=self.embedding_model_name,
            dimensions=self.embedding_model_dim,
        )

        return [
            Document(
                id=str(i),
                meta={"id": str(i)},
                content=ddl_command,
                embedding=embeddings.data[i].embedding,
            )
            for i, ddl_command in enumerate(tqdm(ddl_commands))
        ]

    def _convert_views(self, views: List[Dict[str, Any]]) -> List[str]:
        def _format(view: Dict[str, Any]) -> str:
            properties = view["properties"] if "properties" in view else ""
            return f"/* {properties} */\nCREATE VIEW {view['name']}\nAS ({view['statement']})"

        return [_format(view) for view in views]


if __name__ == "__main__":
    indexing_pipeline = Indexing(
        document_store=init_document_store(),
    )

    print("generating indexing_pipeline.jpg to outputs/pipelines/ask...")
    indexing_pipeline.draw("./outputs/pipelines/ask/indexing_pipeline.jpg")
