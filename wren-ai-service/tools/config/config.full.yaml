type: llm
provider: openai_llm
models:
  - model: gpt-4o-mini
    kwargs:
      {
        "temperature": 0,
        "n": 1,
        "max_tokens": 4096,
        "response_format": { "type": "json_object" },
      }
api_base: https://api.openai.com/v1
timeout: 120

---
type: llm
provider: azure_openai_llm
models:
  - model: gpt-4o
    kwargs:
      {
        "temperature": 0,
        "n": 1,
        "max_tokens": 4096,
        "response_format": { "type": "json_object" },
      }
api_base: https://<your-endpoint>.openai.azure.com/
api_version: "2024-05-13"
timeout: 120

---
type: llm
provider: ollama_llm
models:
  - model: gemma2:9b
    kwargs: { "temperature": 0 }
url: http://localhost:11434
timeout: 120

---
type: embedder
provider: openai_embedder
models:
  - model: text-embedding-3-large
    dimension: 3072
api_base: https://api.openai.com/v1
timeout: 120

---
type: embedder
provider: azure_openai_embedder
models:
  - model: text-embedding-3-small
    dimension: 256
api_base: https://<your-endpoint>.openai.azure.com/
api_version: "2024-05-13"
timeout: 120

---
type: embedder
provider: ollama_embedder
models:
  - model: nomic-embed-text
    dimension: 786
url: http://localhost:11434
timeout: 120

---
type: engine
provider: wren_ui
endpoint: http://localhost:3000

---
type: engine
provider: wren_ibis
endpoint: http://localhost:8000
source: bigquery
manifest: "" # base64 encoded string of the MDL
connection_info: "" # base64 encoded string of the connection info

---
type: engine
provider: wren_engine
endpoint: http://localhost:8080
manifest: ""

---
type: document_store
provider: qdrant
location: http://localhost:6333
embedding_model_dim: 3072
timeout: 120
recreate_index: false

---
type: pipeline
pipes:
  - name: db_schema_indexing
    embedder: openai_embedder.text-embedding-3-large
    document_store: qdrant
  - name: historical_question_indexing
    embedder: openai_embedder.text-embedding-3-large
    document_store: qdrant
  - name: table_description_indexing
    embedder: openai_embedder.text-embedding-3-large
    document_store: qdrant
  - name: db_schema_retrieval
    llm: openai_llm.gpt-4o-mini
    embedder: openai_embedder.text-embedding-3-large
    document_store: qdrant
  - name: historical_question_retrieval
    embedder: openai_embedder.text-embedding-3-large
    document_store: qdrant
  - name: sql_generation
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: sql_correction
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: followup_sql_generation
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: sql_summary
    llm: openai_llm.gpt-4o-mini
  - name: sql_answer
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: sql_breakdown
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: sql_expansion
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: sql_explanation
    llm: openai_llm.gpt-4o-mini
  - name: sql_regeneration
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: semantics_description
    llm: openai_llm.gpt-4o-mini
  - name: relationship_recommendation
    llm: openai_llm.gpt-4o-mini
    engine: wren_ui
  - name: question_recommendation
    llm: openai_llm.gpt-4o-mini
  - name: chart_generation
    llm: openai_llm.gpt-4o-mini
  - name: chart_adjustment
    llm: openai_llm.gpt-4o-mini
  - name: intent_classification
    llm: openai_llm.gpt-4o-mini
    embedder: openai_embedder.text-embedding-3-large
    document_store: qdrant
  - name: data_assistance
    llm: openai_llm.gpt-4o-mini
  - name: sql_executor
    engine: wren_ui
  - name: preprocess_sql_data
    llm: openai_llm.gpt-4o-mini

---
settings:
  host: 127.0.0.1
  port: 5556
  column_indexing_batch_size: 50
  table_retrieval_size: 10
  table_column_retrieval_size: 100
  query_cache_maxsize: 1000
  allow_using_db_schemas_without_pruning: false
  query_cache_ttl: 3600
  langfuse_host: https://cloud.langfuse.com
  langfuse_enable: true
  enable_timer: false
  logging_level: INFO
  development: false
