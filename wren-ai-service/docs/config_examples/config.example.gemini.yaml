# WrenAI Example Configuration for Google Gemini (via LiteLLM)
#
# HOW TO USE:
# 1. RENAME this file to 'config.yaml' and place it in ~/.wrenai/
# 2. CONFIGURE your ~/.wrenai/.env file:
#    # API Key should be in ~/.wrenai/.env as GEMINI_API_KEY after the qdrant seciont as :GEMINI_API_KEY=<api key> <--- Add this line
#    # change this in env WREN_AI_SERVICE_VERSION=0.19.3 <--- Set your WrenAI version here
# 3. ADJUST the settings below if needed:
#    - The 'model' names if you prefer different Gemini models.
#    - Verify the 'pipes' section against the example for your SPECIFIC WrenAI version if you encounter issues.

type: llm
provider: litellm_llm
models:
  # Requires GEMINI_API_KEY in ~/.wrenai/.env
  - model: gemini/gemini-1.5-flash-latest # Using a common, efficient Gemini model
    alias: default                        # Default LLM for most tasks
    timeout: 120
    kwargs:
      n: 1
      temperature: 0
  # Requires GEMINI_API_KEY in ~/.wrenai/.env
  - model: gemini/gemini-1.5-flash-latest # Using the same model for charts, but configured for JSON output
    alias: gemini-llm-for-chart           # Specific LLM alias for chart generation
    timeout: 120
    kwargs:
      n: 1
      temperature: 0
      response_format:                    # Gemini API requires this for JSON mode
        type: json_object

---
type: embedder
provider: litellm_embedder
models:
  # Requires GEMINI_API_KEY in ~/.wrenai/.env
  - model: gemini/text-embedding-004      # Specific Gemini embedding model
    alias: default                        # Default embedding model
    timeout: 120

---
# Standard Engine Endpoints (Usually default in Docker)
type: engine
provider: wren_ui
endpoint: http://wren-ui:3000

---
type: engine
provider: wren_ibis # Include if using features that require Ibis (like sql_functions_retrieval)
endpoint: http://wren-ibis:8000

---
# Document Store (Qdrant)
type: document_store
provider: qdrant
location: http://qdrant:6333
# Embedding dimension for gemini/text-embedding-004 is 768.
embedding_model_dim: 768
timeout: 120
recreate_index: true # Set to false after first run to preserve embeddings

---
# Pipeline Definitions
# Uses aliases defined above (e.g., litellm_llm.default, litellm_llm.gemini-llm-for-chart).
# Verify these pipe definitions against the official example for your WrenAI version if needed:
# Replace <WRENAI_VERSION_NUMBER> with your version (e.g., v0.19.3)
# https://raw.githubusercontent.com/canner/WrenAI/<WRENAI_VERSION_NUMBER>/docker/config.example.yaml
type: pipeline
pipes:
  - name: db_schema_indexing
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: historical_question_indexing
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: table_description_indexing
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: db_schema_retrieval
    llm: litellm_llm.default
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: historical_question_retrieval
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: sql_generation
    llm: litellm_llm.default
    engine: wren_ui
  - name: sql_correction
    llm: litellm_llm.default
    engine: wren_ui
  - name: followup_sql_generation
    llm: litellm_llm.default
    engine: wren_ui
  - name: sql_summary
    llm: litellm_llm.default
  - name: sql_answer
    llm: litellm_llm.default
    engine: wren_ui
  - name: sql_breakdown
    llm: litellm_llm.default
    engine: wren_ui
  - name: sql_expansion
    llm: litellm_llm.default
    engine: wren_ui
  - name: semantics_description
    llm: litellm_llm.default
  - name: relationship_recommendation
    llm: litellm_llm.default
    engine: wren_ui
  - name: question_recommendation
    llm: litellm_llm.default
  - name: question_recommendation_db_schema_retrieval
    llm: litellm_llm.default
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: question_recommendation_sql_generation
    llm: litellm_llm.default
    engine: wren_ui
  - name: chart_generation
    llm: litellm_llm.gemini-llm-for-chart
  - name: chart_adjustment
    llm: litellm_llm.gemini-llm-for-chart
  - name: intent_classification
    llm: litellm_llm.default
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: data_assistance
    llm: litellm_llm.default
  - name: sql_pairs_indexing
    document_store: qdrant
    embedder: litellm_embedder.default
  - name: sql_pairs_retrieval
    document_store: qdrant
    embedder: litellm_embedder.default
    llm: litellm_llm.default
  - name: preprocess_sql_data
    llm: litellm_llm.default
  - name: sql_executor
    engine: wren_ui
  - name: sql_question_generation
    llm: litellm_llm.default
  - name: sql_generation_reasoning
    llm: litellm_llm.default
  - name: followup_sql_generation_reasoning
    llm: litellm_llm.default
  - name: sql_regeneration
    llm: litellm_llm.default
    engine: wren_ui
  - name: instructions_indexing
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: instructions_retrieval
    embedder: litellm_embedder.default
    document_store: qdrant
  - name: sql_functions_retrieval
    engine: wren_ibis
    document_store: qdrant
  - name: project_meta_indexing
    document_store: qdrant

---
# General Settings
settings:
  engine_timeout: 30
  column_indexing_batch_size: 50
  table_retrieval_size: 10
  table_column_retrieval_size: 100
  allow_using_db_schemas_without_pruning: true
  allow_intent_classification: true
  allow_sql_generation_reasoning: true
  query_cache_maxsize: 1000
  query_cache_ttl: 3600
  langfuse_host: https://cloud.langfuse.com
  langfuse_enable: true
  logging_level: DEBUG
  development: true
  historical_question_retrieval_similarity_threshold: 0.9
  sql_pairs_similarity_threshold: 0.7
  sql_pairs_retrieval_max_size: 10
  instructions_similarity_threshold: 0.7
  instructions_top_k: 10