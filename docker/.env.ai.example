## LLM
# openai_llm, azure_openai_llm, ollama_llm
LLM_PROVIDER=openai_llm
LLM_TIMEOUT=120
GENERATION_MODEL=gpt-4o-mini
GENERATION_MODEL_KWARGS={"temperature": 0, "n": 1, "max_tokens": 4096, "response_format": {"type": "json_object"}}
COLUMN_INDEXING_BATCH_SIZE=50
TABLE_RETRIEVAL_SIZE=10
TABLE_COLUMN_RETRIEVAL_SIZE=1000
QUERY_CACHE_TTL=3600

# openai or openai-api-compatible
LLM_OPENAI_API_KEY=sk-xxxx
LLM_OPENAI_API_BASE=https://api.openai.com/v1

# azure_openai
LLM_AZURE_OPENAI_API_KEY=
LLM_AZURE_OPENAI_API_BASE=
LLM_AZURE_OPENAI_VERSION=

# ollama
LLM_OLLAMA_URL=http://host.docker.internal:11434


## EMBEDDER
# openai_embedder, azure_openai_embedder, ollama_embedder
EMBEDDER_PROVIDER=openai_embedder
EMBEDDER_TIMEOUT=120
# supported embedding models providers by qdrant: https://qdrant.tech/documentation/embeddings/
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_MODEL_DIMENSION=3072

# openai or openai-api-compatible
EMBEDDER_OPENAI_API_KEY=sk-xxxx
EMBEDDER_OPENAI_API_BASE=https://api.openai.com/v1

# azure_openai
EMBEDDER_AZURE_OPENAI_API_KEY=
EMBEDDER_AZURE_OPENAI_API_BASE=
EMBEDDER_AZURE_OPENAI_VERSION=

# ollama
EMBEDDER_OLLAMA_URL=http://host.docker.internal:11434


## DOCUMENT_STORE
DOCUMENT_STORE_PROVIDER=qdrant
QDRANT_HOST=qdrant
QDRANT_TIMEOUT=120


## Langfuse: https://langfuse.com/
# empty means disabled
LANGFUSE_ENABLE=
LANGFUSE_SECRET_KEY=
LANGFUSE_PUBLIC_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com
